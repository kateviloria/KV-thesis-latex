

\section{Introduction}
\label{sec:intro}

Neural embeddings have had a large rise in popularity as the go-to method for modelling diachronic text. However, these neural models are not critically evaluated and continue to overlook many of the aims and questions of language change \citep{hengchen2021challenges}. The release of the SemEval-2020 Task 1 on Unsupervised Detection of Lexical Semantic Change (LSC) \citep{schlechtweg-etal-2020-semeval} "laid the groundwork for the first comparative study of computational models of LSC" in English, German, Latin, and Swedish \citep{hengchen2021SBXrushifteval}. There are also no foundations or baselines for what hyperparameter variables yield the highest accuracy for this domain-specific task. However, it has been proven that hyperparameter searches for tasks in LSC are worthwhile and produced large improvements in performance (\citet{kaiser-etal-2020-ims, hengchen2021SBXrushifteval}). This thesis presents the results to a large-scale hyperparameter search using the SemEval-2020 Task 1 corpora. The effects of changes in hyperparameter variables and how the hyperparameters interact with the data are also discussed. Intuitions for future tasks in LSC are proposed and considerations toward corpora being used, language being investigated, and target words (frequency and part-of-speech (POS) tag) for evaluation are put forth. 


\subsection{Research Questions}
%\cmtSH[inline]{This can be higher level. You don't care about SemEval 2020 Task 1, you care about language. But there's no test set for *LANGUAGE*, so you take the next best thing: SemEval 2020 Task 1.}
%\cmtSH{This thesis :)} 
This thesis aims to find and investigate the top-performing models for detecting LSC and examine the relationships between different hyperparameter variables and model performance. This will be done through building a pipeline that will train and evaluate 4000 hyperparameter combinations. It also aims to present considerations regarding data, language, and target words that must be made before training models for LSC by extrapolating from the results collected. 


\subsection{Motivation and Real-World Application}

As with many approaches where linguistics and computational methods intersect, “computational models of word meaning are often taken at face value and not questioned by researchers working on LSC” \citep{hengchen2021challenges}. Evaluating models not only in their performance but also grounded with reasoning based on linguistic theory is crucial. Since models are language-specific and time-specific, assessments in the field of LSC must also be analysed with linguistic and sociological lenses. Through conducting a hyperparameter search, all other variables are controlled and models can be thoroughly evaluated and analyzed through the two lenses mentioned above. 

\citet{hengchen2021challenges} also state that there, understandably so due to the large availability and resources put into creating English corpora, has been a large over-representation of studies performed on English. Although there have been great advances for the English language in this field, these tools and methods are not necessarily transferable or applicable to other languages. By using the SemEval dataset, languages other than English are being represented and evaluated. 

Advancements in the field of LSC would be beneficial to many other fields and real-world applications. LSC approaches can be used by lexicographers in identifying and validating the usages and dates of usage of specific word senses \citep{lau-etal-2012-word, falk-etal-2014-non, klosa-2018-newgerman}. The field of historical linguistics would also benefit from these approaches in order to test the different laws or hypotheses involving how languages change \citep{hamilton-etal-2016-diachronic, Xu2015ACE}. It is also mentioned in \citet{hengchen2021challenges} that these methods are transferable to other fields such as the interpretation of literature in historical research and political science.  

%\cmtKV{is below the better way of citing multiple papers within parentheses}
%(\citet{lau-etal-2012-word,falk-etal-2014-non,klosa-2018-newgerman})\\
%\cmtSH{Here below works better if they need to be within parentheses -- it removes an extra set of ()}
%\citep{lau-etal-2012-word,falk-etal-2014-non,klosa-2018-newgerman}

\subsection{Contributions}
In this thesis, a hyperparameter search tool is built and used to conduct the large-scale hyperparameter search and set a precedence for intuition when choosing hyperparameters for future LSC tasks. Through training various hyperparameter combinations, trends in performance are analysed and recommendations for hyperparameters are substantiated. Important considerations that must be made before training a model for an LSC task include: the language in question, corpora size and text genres, and the frequency and POS-tags of the target words. Performance evaluation of the models by POS-tag showed that some models are better at detecting LSC in certain POS-tags than others. Having the groundwork for which hyperparameter combinations most accurately detects LSC for specific languages and corpora will allow the research area to focus on discerning when a word gains or loses a sense and what those senses are. 


\subsection{Scope}
\label{intro-scope}
Distributional approaches face many criticisms in the field of computational semantics. Through an evaluation of their novel approach that considers syntactic relations and traditional vector-based models, \citet{pado-lapata-2003-constructing} note that traditional semantic space models have a more difficult time differentiating semantic relations between word pairs. Models used today for detecting semantic change still have a difficult time discerning the type of semantic relation or change that is occurring in a vector space. Evaluating the specification of semantic relations and changes between words is not within the scope of this thesis. Performance of the models are based on whether or not a model can accurately detect whether a word has undergone semantic change. The ability to discern whether or not a target word has gained or lost a sense is not evaluated. 

