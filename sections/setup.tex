\section{Experimental Setup}

3.1 Dataset (FORMAT)

The SemEval-2020 Task 1 on Unsupervised Detection of Lexical Semantic Change (ANNOTATION) provides manually-annotated datasets for four languages (English, German, Swedish, and Latin). It is composed of a diachronic corpus pair and a set of target words for each language. Having a gold standard that is based on roughly 100,000 human judgments, researchers now have a more concrete foundation for comparing models. There are two subtasks that differ by the assessment of LSC: binary classification and ranking. In order to identify and evaluate the subtle effects of hyperparameter changes, this thesis follows Subtask 2—based on a ranking of the target words depending on the degree of LSC between the first and second corpus. In contrast to Subtask 1’s binary classification, the method of ranking in Subtask 2 “captures fine-grained changes in the two sense frequency distributions” (ANNOTATION pg2). The two corpora for each language (C1 and C2) were divided based on data size and the availability of target words. Pre-processing of all corpora involved lemmatization, removal of all punctuation, and randomly shuffling sentences within each time-specific corpora. 

The Clean Corpus of Historical American English (CCOHA) consists of different types of text—fiction, non-fiction, magazines, and newspapers—from the 1810s to the 2000s (ANNOTATION, Davies and Alatrash). The first time-bin corpus used for German is Deutsches Textarchiv (DA) which is composed of different genres of text from the 16th-20th centuries (ANNOTATION). For the second time-bin, a combination of the Berliner Zeitung (BZ) and Neues Deutschland (ND) corpora is used (ANNOTATION). Both German corpora are comprised of newspaper articles from the years of 1945-1993. The corpus used for Latin, LatinISE (ANNOTATION, McGillivray and Kilgarriff, 2013), is a compilation of texts originating from 2nd century B.C. to 21st century AD from three online digital libraries. The corpora used for Swedish is the Kubhist corpus (ANNOTATION), which similar to the German corpus used, is a newspaper corpus with articles from the 18th to the 20th century. 

**INSERT TABLE OF CORPORA 

Annotators—all native speakers or former university students of the respective language they were assigned—were instructed to follow the DURel framework (ANNOTATION). Deriving from Blank (1997)’s (ANNOTATION?) continuum of semantic proximity for synchronic polysemy annotation, its semantic-relatedness scale for a target word w within two specific time periods from C1 and C2 resulted in high inter-annotator agreement. 
	
Each language is accompanied by a target word list that consists of words that have undergone semantic change or stable words—words that have not changed in meaning. For words that have changed in meaning, it is not distinguished whether words have lost or gained a sense. Stable words were chosen to act as counterparts of words that have changed in meaning through the consideration of the same POS tag and a comparable/similar frequency development between the two time periods. This consideration minimizes possible model biases that result from these factors. (OUTTA CONTROL ANNOTATION?). Since many of the English target words underwent POS-specific semantic changes, POS tags were concatenated in the target word list (“word\_pos”). The additional information of POS tags presented a great opportunity to also examine model performances for this project (???). The addition of POS tags for the target word lists of the remaining three languages will be discussed further below.
 
** POS TAG BREAK DOWN TABLE

Numerous types of semantic representations were used by teams during the SemEval task: token embeddings vs. type embeddings and topic modelling vs. vector space models. In both Subtask 1 and 2, the highest-performing systems used static-type embedding models. Token embeddings include more contextual information each time the target word appears in the corpus while type embeddings are average embeddings (LACKING). However, it was pointed out that raw corpora, rather than lemmatized corpora, would bode better for token embeddings. (ANNOTATION?) Following the best-performing models of the tasks, with a larger focus on Subtask 2, a hyperparameter search of models with type embeddings would help determine if the top scores of the task could be surpassed solely on changes in hyperparameters. (ENDSOUNDS WEIRD, EDIT)
