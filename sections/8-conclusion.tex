\section{Conclusion}

In this thesis, a large-scale hyperparameter search is conducted for SemEval-2020 Task 1. The hyperparameter search consists of exploring the effects of language, algorithm, alignment method, epochs, dimensions, frequency threshold, and shared vocabulary size for the Orthogonal Procrustes alignment method on detecting LSC. The results are then presented and analysed by discussing the trends within changes in hyperparameter variables for each language's top model. Models were also evaluated in their performance for detecting LSC depending on the target word's POS-tag. Results (Section~\ref{sec:results}) show that performance improvement dramatically decreases after 50 epochs for Latin and German. For all four languages, of which have very different corpus sizes, training for smaller epochs tend to yield better results. The research demonstrates that the general standard of 300 dimensions for vectors, based on past English LSC tasks, does not necessarily apply to other languages. This highlights the importance of conducting research in languages other than English and the shortcomings of generalising language as a whole through the English language. Trends seen in the results of the dimensions, frequency thresholds, and shared vocabulary hyperparameters were also connected to language, corpus size, and text genres. Ultimately, the findings presented provide a concrete foundation and basis to aid in the hyperparameter selection process for future tasks in LSC.

%\cmtSH{for all languages? if yes --> mention it. Also mention that this is shown for all corpus sizes}

%\cmtSH{is "baseline" correct here? perhaps "usual trope"? "generally agreed upon value"?}

% \cmtSH{as a whole} 