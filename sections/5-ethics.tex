\section{Ethical Considerations}
\label{sec:ethicalcons}

Ethical considerations must be made when conducting an experimental research method, as with a hyperparameter search. The effects of conducting this experiment is critically assessed and evaluated through environmental and sociological lenses.

Throughout the process of the hyperparameter search, environmental impact was considered at each step. While adjustments were made to minimise environmental impact, they also help create a more efficient and robust pipeline. As discussed in Section~\ref{exp-ethics}, the project had a total of approximately 430 hours of training and computational time spent and 1.372 kg of CO\textsubscript{2} consumed. For Word2Vec models, the shortest training time was less than 1 second\footnote{Many models had this same training time. An example model trained on the English corpora had the hyperparameters: Alignment=Orthogonal Procrustes, Epochs=5, Dimensions=10, Frequency Threshold=5.} and the longest was around 3 hours and 26 minutes\footnote{This model trained on the Swedish corpora had the hyperparameters: Alignment=Orthogonal Procrustes, Epochs=100, Dimensions=25, Frequency Threshold=100.}. After training all of the model combinations that use the Word2Vec algorithm, results were evaluated and it was decided that not training 160 model combinations that required 100 epochs each of training for FastText would not produce significant or meaningful results. Since FastText aims to create character \emph{n}-gram vector representations, training 100-epoch models would involve much more computational time and memory usage compared to the already large models that were created using Word2Vec. Despite acknowledgments and modifications for minimising consumption and efficiency reasons, a significant amount of energy and memory being used is inevitable during a large-scale hyperparameter search. To ensure that the energy consumed and the space taken is worthwhile, all of the results and pipeline will be available for public access (see \autoref{app-resources}). The POS-tagged word lists and cosine distances for each model will also be available for further analysis and future evaluations. This large-scale hyperparameter search is also well-documented to ensure that it will not have to be done again and future tasks can focus on refining model optimisations. 

Another crucial consideration that must be made is regarding the data and the type of content being used for training models. Humans have written the texts in these corpora and humans are inherently biased. Anonymity is also a concern for researchers when using text as data. Most of the historical texts used for this thesis are quite old, spanning from 2\textsuperscript{nd} century B.C. to 2010 with most of the texts coming from the 1800s-1900s. Given the age of the texts being used, the question of anonymity and privacy is not a large concern for this thesis. Through training, machines inevitably learn the biases from these past texts. Biases such as racism, sexism, homophobia, and other forms of discrimination towards marginalised groups of people can be seen throughout historical texts. \citet{tripodi-etal-2019-tracing} show that antisemitic language can be detected through language change. It is vital to acknowledge that these inherent biases exist within historical texts. Despite releasing these models, which have learned and reinforced these biases, I do not endorse, nor agree with these biases. As \citet{hengchen-tahmasebi_2021-swedishdiachronic} state, the hope is to “shed light on these representations, as ignoring them would mean they have never existed”. 
